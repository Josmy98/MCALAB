{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josmy98/MCALAB/blob/main/bone_fracture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5_HGCO6CIsM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smTeQMaVC0KZ"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "data_dir = \"/content/Bone_Fracture_Binary_Classification\"  # Update this with your dataset path\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf-itsKpd4u_",
        "outputId": "eda87dca-4096-4b1c-ebbe-4507ad4c11aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_path = \"/content/archive (4).zip\"\n",
        "extract_path = \"/content/\"  # Directory where files will be extracted\n",
        "\n",
        "# Open and extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PLVhwp1J9L5"
      },
      "outputs": [],
      "source": [
        " #Image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBfauHyhK0S8",
        "outputId": "33394b96-d0f6-498b-bf2e-6f8a2af1b1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9246 images belonging to 2 classes.\n",
            "Found 829 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train',\n",
        "    target_size=(150, 150),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # or 'categorical' for multi-class\n",
        ")\n",
        "\n",
        "val_generator = valid_datagen.flow_from_directory(\n",
        "    '/content/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-NVwW0lloHp",
        "outputId": "6a50eb39-849f-4087-8d85-8a61b71109b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(150, 150, 3)),  # Explicit Input layer\n",
        "    Conv2D(32, (3,3), activation='relu', kernel_regularizer=l2(0.001), input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu',  kernel_regularizer=l2(0.001)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux1WIn90ZQgl"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3shIkD2qGLyo",
        "outputId": "b21db8fa-102a-4061-f75a-e3b941db7e8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4925 - loss: 0.9653"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 2s/step - accuracy: 0.4925 - loss: 0.9647 - val_accuracy: 0.7105 - val_loss: 0.6740\n",
            "Epoch 2/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 2s/step - accuracy: 0.5577 - loss: 0.7089 - val_accuracy: 0.7008 - val_loss: 0.6735\n",
            "Epoch 3/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 2s/step - accuracy: 0.5914 - loss: 0.6949 - val_accuracy: 0.6683 - val_loss: 0.6537\n",
            "Epoch 4/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 2s/step - accuracy: 0.6280 - loss: 0.6758 - val_accuracy: 0.7105 - val_loss: 0.6082\n",
            "Epoch 5/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 2s/step - accuracy: 0.6656 - loss: 0.6456 - val_accuracy: 0.6031 - val_loss: 0.6945\n",
            "Epoch 6/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 2s/step - accuracy: 0.6738 - loss: 0.6313 - val_accuracy: 0.7334 - val_loss: 0.5976\n",
            "Epoch 7/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 2s/step - accuracy: 0.6808 - loss: 0.6284 - val_accuracy: 0.7153 - val_loss: 0.5973\n",
            "Epoch 8/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 2s/step - accuracy: 0.6951 - loss: 0.6159 - val_accuracy: 0.7214 - val_loss: 0.5851\n",
            "Epoch 9/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 2s/step - accuracy: 0.7002 - loss: 0.6049 - val_accuracy: 0.6767 - val_loss: 0.6392\n",
            "Epoch 10/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 2s/step - accuracy: 0.7108 - loss: 0.6089 - val_accuracy: 0.7612 - val_loss: 0.5395\n",
            "Epoch 11/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 2s/step - accuracy: 0.7129 - loss: 0.6078 - val_accuracy: 0.7551 - val_loss: 0.5494\n",
            "Epoch 12/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 2s/step - accuracy: 0.7330 - loss: 0.5880 - val_accuracy: 0.7648 - val_loss: 0.5661\n",
            "Epoch 13/20\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 2s/step - accuracy: 0.7340 - loss: 0.5834 - val_accuracy: 0.7913 - val_loss: 0.5168\n",
            "Epoch 14/20\n",
            "\u001b[1m 43/289\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:26\u001b[0m 2s/step - accuracy: 0.7461 - loss: 0.5688"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sWISJImy6NZ"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUvTwoXeYAmq",
        "outputId": "8808f858-6fe5-479b-876b-0b640d697275"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "model.save(\"bone_fracture_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXCiRWbwOd-s",
        "outputId": "76a32e86-bba9-46fc-c815-0a6afcad2c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training complete. Saved as 'bone_fracture_model.h5'\n"
          ]
        }
      ],
      "source": [
        "print(\"Model training complete. Saved as 'bone_fracture_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EecSODy4grlh",
        "outputId": "3425e687-3c17-4bd4-d2a0-853dc4bd31b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "❌ Fracture Detected\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "def predict_fracture(image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(image_path, target_size=(150, 150))  # Changed to (150, 150)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = img_array / 255.0  # Normalize (if needed)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Interpret result\n",
        "    if prediction[0][0] > 0.5:\n",
        "        print(\"❌ Fracture Detected\")\n",
        "    else:\n",
        "        print(\"✅ No Fracture Detected\")\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/0047.png\"  # Replace with your image path\n",
        "predict_fracture(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD1DUwKUwR-u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wrw8D5EhfL33"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkzCHa13P+tyC+X9QOH4Xm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}